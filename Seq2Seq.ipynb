{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "语料库句子数量： 5\n"
     ]
    }
   ],
   "source": [
    "# 构建语料库，包含中文，解码器输入英文，翻译后的目标输出英文\n",
    "corpus = [\n",
    "    ['咖哥 喜欢 小冰', '<sos> KaGe likes XiaoBing', 'KaGe likes XiaoBing <eos>'],\n",
    "    ['我 爱 学习 人工智能', '<sos> I love studying AI', 'I love studying AI <eos>'],\n",
    "    ['深度学习 改变 世界', '<sos> DL changed the world', 'DL changed the world <eos>'],\n",
    "    ['自然 语言 处理 很 强大', '<sos> NLP is so powerful', 'NLP is so powerful <eos>'],\n",
    "    ['神将网络 非常 复杂', '<sos> Neural-Nets are complex', 'Neural-Nets are complex <eos>']\n",
    "]\n",
    "print('语料库句子数量：', len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文词汇表词汇数量： 18\n",
      "英文词汇表词汇数量： 18\n"
     ]
    }
   ],
   "source": [
    "# 构建中英词汇表\n",
    "word_vocabulary_cn = []\n",
    "word_vocabulary_en = []\n",
    "\n",
    "for sentence in corpus:\n",
    "    for token in sentence[0].split():\n",
    "        if token not in word_vocabulary_cn:\n",
    "            word_vocabulary_cn.append(token)\n",
    "    \n",
    "    for token in sentence[1].split():\n",
    "        if token not in word_vocabulary_en:\n",
    "            word_vocabulary_en.append(token)\n",
    "\n",
    "    for token in sentence[2].split():\n",
    "        if token not in word_vocabulary_en:\n",
    "            word_vocabulary_en.append(token)\n",
    "\n",
    "len_word_vocabulary_cn = len(word_vocabulary_cn)\n",
    "len_word_vocabulary_en = len(word_vocabulary_en)\n",
    "print('中文词汇表词汇数量：', len_word_vocabulary_cn)\n",
    "print('英文词汇表词汇数量：', len_word_vocabulary_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文词汇索引表 {'咖哥': 0, '喜欢': 1, '小冰': 2, '我': 3, '爱': 4, '学习': 5, '人工智能': 6, '深度学习': 7, '改变': 8, '世界': 9, '自然': 10, '语言': 11, '处理': 12, '很': 13, '强大': 14, '神将网络': 15, '非常': 16, '复杂': 17}\n",
      "英文词汇索引表 {'<sos>': 0, 'KaGe': 1, 'likes': 2, 'XiaoBing': 3, '<eos>': 4, 'I': 5, 'love': 6, 'studying': 7, 'AI': 8, 'DL': 9, 'changed': 10, 'the': 11, 'world': 12, 'NLP': 13, 'is': 14, 'so': 15, 'powerful': 16, 'Neural-Nets': 17, 'are': 18, 'complex': 19}\n",
      "索引中文词汇表 {0: '咖哥', 1: '喜欢', 2: '小冰', 3: '我', 4: '爱', 5: '学习', 6: '人工智能', 7: '深度学习', 8: '改变', 9: '世界', 10: '自然', 11: '语言', 12: '处理', 13: '很', 14: '强大', 15: '神将网络', 16: '非常', 17: '复杂'}\n",
      "索引英文词汇表 {0: '<sos>', 1: 'KaGe', 2: 'likes', 3: 'XiaoBing', 4: '<eos>', 5: 'I', 6: 'love', 7: 'studying', 8: 'AI', 9: 'DL', 10: 'changed', 11: 'the', 12: 'world', 13: 'NLP', 14: 'is', 15: 'so', 16: 'powerful', 17: 'Neural-Nets', 18: 'are', 19: 'complex'}\n"
     ]
    }
   ],
   "source": [
    "# 构建中英字典词表\n",
    "word_vocabulary_cn_to_index_vocabulary = {token : index for index, token in enumerate(word_vocabulary_cn)}\n",
    "word_vocabulary_en_to_index_vocabulary = {token : index for index, token in enumerate(word_vocabulary_en)}\n",
    "index_vocabulary_to_word_vocabulary_cn = {index : token for index, token in enumerate(word_vocabulary_cn)}\n",
    "index_vocabulary_to_word_vocabulary_en = {index : token for index, token in enumerate(word_vocabulary_en)}\n",
    "print('中文词汇索引表', word_vocabulary_cn_to_index_vocabulary)\n",
    "print('英文词汇索引表', word_vocabulary_en_to_index_vocabulary)\n",
    "print('索引中文词汇表', index_vocabulary_to_word_vocabulary_cn)\n",
    "print('索引英文词汇表', index_vocabulary_to_word_vocabulary_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码器输入: tensor([[7, 8, 9]])\n",
      "编码器输入形状： torch.Size([1, 3])\n",
      "解码器输入: tensor([[7, 8, 9]])\n",
      "解码器输入形状： torch.Size([1, 5])\n",
      "目标: tensor([[7, 8, 9]])\n",
      "目标形状： torch.Size([1, 5])\n",
      "原始句子： ['深度学习 改变 世界', '<sos> DL changed the world', 'DL changed the world <eos>']\n"
     ]
    }
   ],
   "source": [
    "# 生成训练数据\n",
    "def make_train_data(corpus):\n",
    "    sentence = random.choice(corpus)\n",
    "    encoder_input = torch.tensor([[word_vocabulary_cn_to_index_vocabulary[token] for token in sentence[0].split()]])\n",
    "    decoder_input = torch.tensor([[word_vocabulary_en_to_index_vocabulary[token] for token in sentence[1].split()]])\n",
    "    target = torch.tensor([[word_vocabulary_en_to_index_vocabulary[token] for token in sentence[2].split()]])\n",
    "    return encoder_input, decoder_input, target\n",
    "\n",
    "# 验证\n",
    "encoder_input, decoder_input, target = make_train_data(corpus)\n",
    "print('编码器输入:', encoder_input)\n",
    "print('编码器输入形状：', encoder_input.size())\n",
    "print('解码器输入:', encoder_input)\n",
    "print('解码器输入形状：', decoder_input.size())\n",
    "print('目标:', encoder_input)\n",
    "print('目标形状：', target.size())\n",
    "for sentence in corpus:\n",
    "    if all(word_vocabulary_cn_to_index_vocabulary[token] in encoder_input for token in sentence[0].split()):\n",
    "    # all(iterable)判断可迭代对象所有元素是否满足某个条件，如果所有元素都为True或等价于True的值，则返回True，否则返回False\n",
    "    # 如果可迭代对象为空，则返回True，没有元素违反条件\n",
    "    # 短路操作，一旦遇到第一个False，就会立即返回False\n",
    "        original_sentence = sentence\n",
    "        break\n",
    "print('原始句子：', original_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建编码器和解码器架构\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        output, hidden = self.rnn(self.embedding(inputs), hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        output, hidden = self.rnn(self.embedding(inputs), hidden)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码器结构：\n",
      " Encoder(\n",
      "  (embedding): Embedding(18, 128)\n",
      "  (rnn): RNN(128, 128, batch_first=True)\n",
      ")\n",
      "解码器结构：\n",
      " Decoder(\n",
      "  (embedding): Embedding(20, 128)\n",
      "  (rnn): RNN(128, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=20, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "encoder = Encoder(len_word_vocabulary_cn, hidden_size)\n",
    "decoder = Decoder(len_word_vocabulary_en, hidden_size)\n",
    "print('编码器结构：\\n', encoder)\n",
    "print('解码器结构：\\n', decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建编码器-解码器架构\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super().__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "\n",
    "    def forward(self, encoder_input, hidden, decoder_input):\n",
    "        _, encoder_hidden = self.Encoder(encoder_input, hidden)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_output, _ = self.Decoder(decoder_input, decoder_hidden)\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码器-解码器架构：\n",
      " Seq2Seq(\n",
      "  (Encoder): Encoder(\n",
      "    (embedding): Embedding(18, 128)\n",
      "    (rnn): RNN(128, 128, batch_first=True)\n",
      "  )\n",
      "  (Decoder): Decoder(\n",
      "    (embedding): Embedding(20, 128)\n",
      "    (rnn): RNN(128, 128, batch_first=True)\n",
      "    (fc): Linear(in_features=128, out_features=20, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(encoder, decoder)\n",
    "print('编码器-解码器架构：\\n', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "def train(model, criterion, optimizer, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        encoder_input, decoder_input, target = make_train_data(corpus)\n",
    "        hidden = torch.zeros(1, encoder_input.size(0), hidden_size)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(encoder_input, hidden, decoder_input)\n",
    "        loss = criterion(output.view(-1, len_word_vocabulary_en), target.view(-1))\n",
    "        if (epoch + 1) % 40 == 0:\n",
    "            print(f'Epoch：{epoch + 1} cost = {loss:.6f}')\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch：40 cost = 0.241193\n",
      "Epoch：80 cost = 0.064824\n",
      "Epoch：120 cost = 0.032962\n",
      "Epoch：160 cost = 0.035060\n",
      "Epoch：200 cost = 0.019002\n",
      "Epoch：240 cost = 0.015831\n",
      "Epoch：280 cost = 0.011321\n",
      "Epoch：320 cost = 0.009127\n",
      "Epoch：360 cost = 0.008043\n",
      "Epoch：400 cost = 0.005759\n"
     ]
    }
   ],
   "source": [
    "epochs = 400\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train(model, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text(model, text_sentence):\n",
    "    encoder_input = torch.tensor([[word_vocabulary_cn_to_index_vocabulary[token] for token in text_sentence.split()]])\n",
    "    decoder_input = torch.tensor([word_vocabulary_en_to_index_vocabulary['<sos>']] +\n",
    "                                  [word_vocabulary_en_to_index_vocabulary['<eos>']] *\n",
    "                                  (len(encoder_input[0] - 1)))\n",
    "    decoder_input = decoder_input.unsqueeze(0)\n",
    "    hidden = torch.zeros(1, encoder_input.size(0), hidden_size)\n",
    "    predict = model(encoder_input, hidden, decoder_input)\n",
    "    predict = predict.max(2, keepdim=True)[1]\n",
    "    print(text_sentence, '--->', [index_vocabulary_to_word_vocabulary_en[n.item()] for n in predict.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "咖哥 喜欢 小冰 ---> ['KaGe', 'likes', 'XiaoBing', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "text(model, '咖哥 喜欢 小冰')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然 语言 处理 很 强大 ---> ['NLP', 'is', 'so', '<eos>', '<eos>', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "text(model, '自然 语言 处理 很 强大')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
