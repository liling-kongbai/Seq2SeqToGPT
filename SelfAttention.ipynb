{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity_score:\n",
      " tensor([[[ 3.5084,  1.3105, -0.1577],\n",
      "         [ 1.3105,  1.6413,  1.1346],\n",
      "         [-0.1577,  1.1346,  1.2624]]])\n",
      "scale_factor:\n",
      " 1.7320508075688772\n",
      "scale_weight:\n",
      " tensor([[[ 2.0255,  0.7566, -0.0911],\n",
      "         [ 0.7566,  0.9476,  0.6551],\n",
      "         [-0.0911,  0.6551,  0.7288]]])\n",
      "attn_weight:\n",
      " tensor([[[0.7135, 0.2006, 0.0859],\n",
      "         [0.3211, 0.3887, 0.2901],\n",
      "         [0.1859, 0.3920, 0.4221]]])\n",
      "attn_output:\n",
      " tensor([[[-0.0300, -3.4212,  4.6600,  4.9364],\n",
      "         [-1.2434,  0.0689,  2.8418,  3.4408],\n",
      "         [-1.2856,  1.5648,  0.9370,  1.4410]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 4)\n",
    "similarity_score = torch.matmul(x, x.transpose(-2, -1))\n",
    "print('similarity_score:\\n', similarity_score)\n",
    "scale_factor = similarity_score.size(-1) ** 0.5\n",
    "print('scale_factor:\\n', scale_factor)\n",
    "scale_weight = similarity_score / scale_factor\n",
    "print('scale_weight:\\n', scale_weight)\n",
    "attn_weight = F.softmax(scale_weight, dim=-1)\n",
    "print('attn_weight:\\n', attn_weight)\n",
    "attn_output = torch.matmul(similarity_score, x)\n",
    "print('attn_output:\\n', attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity_score:\n",
      " tensor([[[-0.2914, -1.6899, -2.9672],\n",
      "         [ 1.0930,  1.2264, -1.1606],\n",
      "         [ 1.0243,  1.2084,  0.7361]]], grad_fn=<UnsafeViewBackward0>)\n",
      "scale_factor:\n",
      " 1.7320508075688772\n",
      "scale_weight:\n",
      " tensor([[[-0.1682, -0.9757, -1.7131],\n",
      "         [ 0.6311,  0.7081, -0.6701],\n",
      "         [ 0.5914,  0.6977,  0.4250]]], grad_fn=<DivBackward0>)\n",
      "attn_weight:\n",
      " tensor([[[0.6027, 0.2688, 0.1286],\n",
      "         [0.4251, 0.4592, 0.1157],\n",
      "         [0.3380, 0.3759, 0.2862]]], grad_fn=<SoftmaxBackward0>)\n",
      "attn_output:\n",
      " tensor([[[-8.6620,  2.5163, -0.4450,  1.2735],\n",
      "         [-2.0277, -0.3835, -3.0741, -2.9376],\n",
      "         [ 2.7943, -1.3640, -1.6057, -2.1431]]], grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 4)\n",
    "\n",
    "linear_q = nn.Linear(4, 4)\n",
    "linear_k = nn.Linear(4, 4)\n",
    "linear_v = nn.Linear(4, 4)\n",
    "\n",
    "Q = linear_q(x)\n",
    "K = linear_k(x)\n",
    "V = linear_v(x)\n",
    "\n",
    "similarity_score = torch.matmul(Q, K.transpose(-2, -1))\n",
    "print('similarity_score:\\n', similarity_score)\n",
    "scale_factor = similarity_score.size(-1) ** 0.5\n",
    "print('scale_factor:\\n', scale_factor)\n",
    "scale_weight = similarity_score / scale_factor\n",
    "print('scale_weight:\\n', scale_weight)\n",
    "attn_weight = F.softmax(scale_weight, dim=-1)\n",
    "print('attn_weight:\\n', attn_weight)\n",
    "attn_output = torch.matmul(similarity_score, V)\n",
    "print('attn_output:\\n', attn_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
